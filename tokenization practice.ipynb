{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed8e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\punith\n",
      "[nltk_data]     yc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dff83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\punith yc\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6a2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" hello! welcome to youtube nlp tutorial\n",
    "please do watch the entire course to master the nlp\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ae2d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hello! welcome to youtube nlp tutorial\\nplease do watch the entire course to master the nlp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162df3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb56275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " '!',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'youtube',\n",
       " 'nlp',\n",
       " 'tutorial',\n",
       " 'please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " 'to',\n",
       " 'master',\n",
       " 'the',\n",
       " 'nlp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2666ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6181a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " '!',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'youtube',\n",
       " 'nlp',\n",
       " 'tutorial',\n",
       " 'please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " 'to',\n",
       " 'master',\n",
       " 'the',\n",
       " 'nlp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8176735",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560681f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programms\",\"history\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfe70b",
   "metadata": {},
   "source": [
    "### porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ea2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55e8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eaten\n",
      "writing-->write\n",
      "writes-->write\n",
      "programming-->program\n",
      "programms-->programm\n",
      "history-->histori\n",
      "finally-->final\n",
      "finalize-->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f7fdb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0b8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "st=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c86775a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c872d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b0f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\punith\n",
      "[nltk_data]     yc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172f2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wn=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf286bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulation'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize(\"congratulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec7950f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'universal'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize(\"universal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c9c0896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "340dbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programms\",\"history\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e98121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eating\n",
      "eats-->eats\n",
      "eaten-->eaten\n",
      "writing-->writing\n",
      "writes-->writes\n",
      "programming-->programming\n",
      "programms-->programms\n",
      "history-->history\n",
      "finally-->finally\n",
      "finalize-->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+wn.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bb9d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eat\n",
      "eats-->eat\n",
      "eaten-->eat\n",
      "writing-->write\n",
      "writes-->write\n",
      "programming-->program\n",
      "programms-->programms\n",
      "history-->history\n",
      "finally-->finally\n",
      "finalize-->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+wn.lemmatize((word),pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6676f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eating\n",
      "eats-->eats\n",
      "eaten-->eaten\n",
      "writing-->writing\n",
      "writes-->writes\n",
      "programming-->programming\n",
      "programms-->programms\n",
      "history-->history\n",
      "finally-->finally\n",
      "finalize-->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+wn.lemmatize((word),pos=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba920dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eating\n",
      "eats-->eats\n",
      "eaten-->eaten\n",
      "writing-->writing\n",
      "writes-->writes\n",
      "programming-->programming\n",
      "programms-->programms\n",
      "history-->history\n",
      "finally-->finally\n",
      "finalize-->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+wn.lemmatize((word),pos=\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bec87a5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-->eating\n",
      "eats-->eats\n",
      "eaten-->eaten\n",
      "writing-->writing\n",
      "writes-->writes\n",
      "programming-->programming\n",
      "programms-->programms\n",
      "history-->history\n",
      "finally-->finally\n",
      "finalize-->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-->\"+wn.lemmatize((word),pos=\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd2cbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"\"\"he is a good boy\n",
    "        she is a good girl\n",
    "        boy and girl are good\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb3c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "184710bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68cbc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=word_tokenize(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ea1b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'boy',\n",
       " 'she',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'girl',\n",
       " 'boy',\n",
       " 'and',\n",
       " 'girl',\n",
       " 'are',\n",
       " 'good']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38566ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=cv.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fe89ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he': 5,\n",
       " 'is': 6,\n",
       " 'good': 4,\n",
       " 'boy': 2,\n",
       " 'she': 7,\n",
       " 'girl': 3,\n",
       " 'and': 0,\n",
       " 'are': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f879c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0]]\n",
      "[[0 0 0 0 0 0 1 0]]\n",
      "[[0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 1 0 0 0]]\n",
      "[[0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 1]]\n",
      "[[0 0 0 0 0 0 1 0]]\n",
      "[[0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dim[0].toarray())\n",
    "print(dim[1].toarray())\n",
    "print(dim[2].toarray())\n",
    "print(dim[3].toarray())\n",
    "print(dim[4].toarray())\n",
    "print(dim[5].toarray())\n",
    "print(dim[6].toarray())\n",
    "print(dim[7].toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d46483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47eecb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':[\"people watch campusx\",\"campusx watch campusx\",\"people write comment\",\"campusx write comment\"],\"output\":[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab2d8e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "511a369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8f499a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b13830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "259fad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79e56a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n",
      "[[0 1 1 0 1]]\n",
      "[[1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(df[0].toarray())\n",
    "print(df[1].toarray())\n",
    "print(df[2].toarray())\n",
    "print(df[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17c04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"he is a good boy\",\"she is a good girl\",\"boy and girl are good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef06571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(text,columns=[\"abc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4817a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0142a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b381e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=cv.fit_transform(df1['abc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34991326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': 5, 'is': 6, 'good': 4, 'boy': 2, 'she': 7, 'girl': 3, 'and': 0, 'are': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "866fe7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 1 1 0]]\n",
      "[[0 0 0 1 1 0 1 1]]\n",
      "[[1 1 1 1 1 0 0 0]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "row index (3) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:44\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m---> 44\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_indices(key)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:152\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    150\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mM \u001b[38;5;129;01mor\u001b[39;00m row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m M:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow index (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m row)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    154\u001b[0m     row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m M\n",
      "\u001b[1;31mIndexError\u001b[0m: row index (3) out of range"
     ]
    }
   ],
   "source": [
    "print(df1[0].toarray())\n",
    "print(df1[1].toarray())\n",
    "print(df1[2].toarray())\n",
    "print(df1[3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29879eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c29c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':[\"people watch campusx\",\"campusx watch campusx\",\"people write comment\",\"campusx write comment\"],\"output\":[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b092619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34141cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(2,2))\n",
    "dim=cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5951bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e2228aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch campusx': 2, 'campusx watch campusx': 0, 'people write comment': 3, 'campusx write comment': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(3,3))\n",
    "dim=cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22b8e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 4, 'watch': 7, 'campusx': 0, 'people watch': 5, 'watch campusx': 8, 'campusx watch': 1, 'write': 9, 'comment': 3, 'people write': 6, 'write comment': 10, 'campusx write': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "dim=cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "860cd89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 6, 'watch': 11, 'campusx': 0, 'people watch': 7, 'watch campusx': 12, 'people watch campusx': 8, 'campusx watch': 1, 'campusx watch campusx': 2, 'write': 13, 'comment': 5, 'people write': 9, 'write comment': 14, 'people write comment': 10, 'campusx write': 3, 'campusx write comment': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,3))\n",
    "dim=cv.fit_transform(df['text'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea150adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':[\"people watch campusx\",\"campusx watch campusx\",\"people write comment\",\"campusx write comment\"],\"output\":[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d01909a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06d18065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb957a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
